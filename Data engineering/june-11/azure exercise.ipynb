{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3b5dfd5-01e5-4426-a5b3-7a02e58efb00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Intialization of SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d633c09-de34-4e25-abed-c5682fb5817e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=3525126442407722#setting/sparkui/0611-043339-3vb7b9iv/driver-5079266641301177846\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7b2cce33c6d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Employee Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e46f78d-460d-4da1-a1f7-bdfe8d42fbdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Creating Data Manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd401cd6-7fd5-4f6b-871b-a8f57d27255d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [ \n",
    "    (\"Ananya\", \"HR\", 52000), \n",
    "    (\"Rahul\", \"Engineering\", 65000), \n",
    "    (\"Priya\", \"Engineering\", 60000), \n",
    "    (\"Zoya\", \"Marketing\", 48000), \n",
    "    (\"Karan\", \"HR\", 53000), \n",
    "    (\"Naveen\", \"Engineering\", 70000), \n",
    "    (\"Fatima\", \"Marketing\", 45000) \n",
    "]\n",
    "columns = [\"Name\", \"Department\", \"Salary\"]\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7afc0d8-1353-4fb3-829b-ad27872ef198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Exercise Set 1: Basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae36200d-3918-499f-959e-a1e312c734ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+\n|  Name| Department|Salary|\n+------+-----------+------+\n|Ananya|         HR| 52000|\n| Rahul|Engineering| 65000|\n| Priya|Engineering| 60000|\n|  Zoya|  Marketing| 48000|\n| Karan|         HR| 53000|\n|Naveen|Engineering| 70000|\n|Fatima|  Marketing| 45000|\n+------+-----------+------+\n\nroot\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Salary: long (nullable = true)\n\nTotal employees: 7\n"
     ]
    }
   ],
   "source": [
    "# 1.Display all records in the DataFrame\n",
    "df.show()\n",
    "# 2.Print the schema of the DataFrame\n",
    "df.printSchema()\n",
    "# 3.Count total number of employees\n",
    "print(\"Total employees:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24c901d2-9022-4987-8016-2c79a9706551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Exercise Set 2: Column Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ea19ee-94c5-46de-bec4-7b46af5037e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-------+\n|  Name| Department|Salary|  Bonus|\n+------+-----------+------+-------+\n|Ananya|         HR| 52000| 7800.0|\n| Rahul|Engineering| 65000| 9750.0|\n| Priya|Engineering| 60000| 9000.0|\n|  Zoya|  Marketing| 48000| 7200.0|\n| Karan|         HR| 53000| 7950.0|\n|Naveen|Engineering| 70000|10500.0|\n|Fatima|  Marketing| 45000| 6750.0|\n+------+-----------+------+-------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Ananya|         HR| 52000| 7800.0|59800.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "# 4.Add a new column Bonus which is 15% of Salary.\n",
    "bonus = df.withColumn(\"Bonus\", round(col(\"Salary\") * 0.15, 2))\n",
    "bonus.show()\n",
    "# 5.Add a new column NetPay = Salary + Bonus\n",
    "netpay = bonus.withColumn(\"NetPay\", col(\"Salary\") + col(\"Bonus\"))\n",
    "netpay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb301cd8-ed6b-45eb-bcca-10d17c05c301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Exercise Set 3: Filtering and Conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26304e8e-5fb4-40a7-b16c-0e7089c3a010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees from Engineering\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\nEmployees with Salary > 60000\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\nEmployees not in Marketing\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Ananya|         HR| 52000| 7800.0|59800.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 6.Display only employees from the “Engineering” department\n",
    "print(\"Employees from Engineering\")\n",
    "netpay.filter(col(\"Department\") == \"Engineering\").show()\n",
    "# 7.Display employees whose salary is greater than 60000\n",
    "print(\"Employees with Salary > 60000\")\n",
    "netpay.filter(col(\"Salary\") > 60000).show()\n",
    "# 8.Display employees who are not in the “Marketing” department\n",
    "print(\"Employees not in Marketing\")\n",
    "netpay.filter(col(\"Department\") != \"Marketing\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e751bf77-b6a3-4cdd-9af6-752b5e8c6fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Exercise Set 4: Sorting and Limiting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6e7c9b8-50d0-49c7-8bf0-44aff3e40b92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 highest paid employees\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Naveen|Engineering| 70000|10500.0|80500.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n+------+-----------+------+-------+-------+\nonly showing top 3 rows\n\nSort by Department ASC and Salary DESC\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Naveen|Engineering| 70000|10500.0|80500.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Ananya|         HR| 52000| 7800.0|59800.0|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9.Show top 3 highest paid employees\n",
    "print(\"Top 3 highest paid employees\")\n",
    "netpay.orderBy(col(\"Salary\").desc()).show(3)\n",
    "# 10.Sort the data by Department ascending and Salary descending\n",
    "print(\"Sort by Department ASC and Salary DESC\")\n",
    "netpay.orderBy(col(\"Department\").asc(), col(\"Salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1682783-6ff1-423d-8338-52dcf9d559f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Exercise Set 5: String and Case Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6ed9783-b9e1-4054-81c5-31b18d094e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add Level column based on Salary\n+------+-----------+------+-------+-------+------+\n|  Name| Department|Salary|  Bonus| NetPay| Level|\n+------+-----------+------+-------+-------+------+\n|Ananya|         HR| 52000| 7800.0|59800.0|   Mid|\n| Rahul|Engineering| 65000| 9750.0|74750.0|Senior|\n| Priya|Engineering| 60000| 9000.0|69000.0|   Mid|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|Junior|\n| Karan|         HR| 53000| 7950.0|60950.0|   Mid|\n|Naveen|Engineering| 70000|10500.0|80500.0|Senior|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|Junior|\n+------+-----------+------+-------+-------+------+\n\nConverted all names to uppercase\n+------+-----------+------+-------+-------+------+\n|  Name| Department|Salary|  Bonus| NetPay| Level|\n+------+-----------+------+-------+-------+------+\n|ANANYA|         HR| 52000| 7800.0|59800.0|   Mid|\n| RAHUL|Engineering| 65000| 9750.0|74750.0|Senior|\n| PRIYA|Engineering| 60000| 9000.0|69000.0|   Mid|\n|  ZOYA|  Marketing| 48000| 7200.0|55200.0|Junior|\n| KARAN|         HR| 53000| 7950.0|60950.0|   Mid|\n|NAVEEN|Engineering| 70000|10500.0|80500.0|Senior|\n|FATIMA|  Marketing| 45000| 6750.0|51750.0|Junior|\n+------+-----------+------+-------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, upper\n",
    "# 11. Add Level column based on Salary\n",
    "level =netpay.withColumn(\"Level\", \n",
    "    when(col(\"Salary\") > 60000, \"Senior\")\n",
    "    .when((col(\"Salary\") >= 50000) & (col(\"Salary\") <= 60000), \"Mid\")\n",
    "    .otherwise(\"Junior\")\n",
    ")\n",
    "print(\"Add Level column based on Salary\")\n",
    "level.show()\n",
    "# 12. Convert all names to uppercase\n",
    "final = level.withColumn(\"Name\", upper(col(\"Name\")))\n",
    "print(\"Converted all names to uppercase\")\n",
    "final.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9055630e-23e2-48a9-856e-d731342d7be6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "azure exercise",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}