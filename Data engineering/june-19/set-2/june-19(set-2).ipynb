{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd177b6c-c797-4cf2-bbe4-2dd54f0a5d36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Intialize the SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4c9945-a7c7-4300-a202-dae36ac9209f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=3525126442407722#setting/sparkui/0611-043339-3vb7b9iv/driver-9097877764254449765\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d37e81c8950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder\\\n",
    "      .appName(\"course-enrollement Analysis\")\\\n",
    "      .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ec314a-1d59-40d9-8715-e5f51cb30fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ingestion & Time Fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f07db6c9-4818-43ba-8e82-52f560ba2fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- EnrollID: string (nullable = true)\n |-- UserID: string (nullable = true)\n |-- CourseID: string (nullable = true)\n |-- CourseName: string (nullable = true)\n |-- Category: string (nullable = true)\n |-- EnrollDate: date (nullable = true)\n |-- CompletionDate: date (nullable = true)\n |-- ProgressPercent: integer (nullable = true)\n |-- Rating: integer (nullable = true)\n\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|          NULL|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|          NULL|\n|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|\n|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load into PySpark with inferred schema\n",
    "#Convert EnrollDate and CompletionDate to \n",
    "#Add DaysToComplete column if completed\n",
    "from pyspark.sql.functions import to_date, datediff, coalesce, col\n",
    "df=spark.read.option(\"header\", True).option(\"inferSchema\", True) \\\n",
    "    .csv(\"file:/Workspace/Shared/course_enrollments.csv\")\n",
    "df.printSchema()\n",
    "df = df.withColumn(\"EnrollDate\", to_date(\"EnrollDate\", \"yyyy-MM-dd\")) \\\n",
    "       .withColumn(\"CompletionDate\", to_date(\"CompletionDate\", \"yyyy-MM-dd\")) \\\n",
    "       .withColumn(\"DaysToComplete\",\n",
    "           datediff(\"CompletionDate\", \"EnrollDate\"))\n",
    "df.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60cafbfe-740d-44fa-9070-f3ceaa019550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**User Learning Path Progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69c3a12f-43b1-4893-9565-a155ef00a68d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-----------+----------------+\n|UserID|CoursesEnrolled|AvgProgress|CompletedCourses|\n+------+---------------+-----------+----------------+\n|  U004|              1|      100.0|               1|\n|  U002|              1|       45.0|               0|\n|  U003|              1|      100.0|               1|\n|  U001|              2|       65.0|               1|\n+------+---------------+-----------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Group by UserID : count of courses enrolled\n",
    "#Avg progress % across all enrollments\n",
    "#Flag IsCompleted = ProgressPercent = 100\n",
    "from pyspark.sql.functions import *\n",
    "progress = df.groupBy(\"UserID\") \\\n",
    "    .agg(\n",
    "      count(\"*\").alias(\"CoursesEnrolled\"),\n",
    "      avg(\"ProgressPercent\").alias(\"AvgProgress\"),\n",
    "      sum(when(col(\"ProgressPercent\") == 100, 1).otherwise(0)).alias(\"CompletedCourses\")\n",
    "    )\n",
    "progress.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4614b5f7-e797-4c07-bb2e-469b0a6385d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Engagement Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9801ef0-18aa-4f7b-b356-bdc45bbb071a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngagementScore:\n+------+-----------------+---------------+------+---------------+\n|UserID|       CourseName|ProgressPercent|Rating|EngagementScore|\n+------+-----------------+---------------+------+---------------+\n|  U001|    Python Basics|            100|     4|            400|\n|  U002|Excel for Finance|             45|     0|              0|\n|  U001|  ML with PySpark|             30|     0|              0|\n|  U003|    Python Basics|            100|     5|            500|\n|  U004|Digital Marketing|            100|     4|            400|\n+------+-----------------+---------------+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Create a score: ProgressPercent * Rating (if not null)\n",
    "#Replace null Rating with 0 before computing\n",
    "df = df.withColumn(\"Rating\", coalesce(col(\"Rating\"), lit(0)))\n",
    "print(\"EngagementScore:\")\n",
    "df = df.withColumn(\"EngagementScore\", col(\"ProgressPercent\") * col(\"Rating\"))\n",
    "df.select(\"UserID\", \"CourseName\", \"ProgressPercent\", \"Rating\", \"EngagementScore\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94bf7998-b047-4fd2-b722-48e257faa380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Identify Drop-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35de503b-29c0-4198-9d59-2eb22c785fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter all records with ProgressPercent < 50 and CompletionDate is null\n",
    "#Create a view called Dropouts\n",
    "df.createOrReplaceTempView(\"enrollments\")\n",
    "spark.sql(\"\"\"\n",
    "  CREATE OR REPLACE TEMP VIEW Dropouts AS\n",
    "  SELECT *\n",
    "  FROM enrollments\n",
    "  WHERE ProgressPercent < 50\n",
    "    AND CompletionDate IS NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d945f6f4-ccf2-4604-8b4f-b22061fe2773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Joins with Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3175ab7-7d0a-4d31-b7ac-0503c2d7807b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Progress by Instructor\n+-------------+-----------+\n|   Instructor|AvgProgress|\n+-------------+-----------+\n|Abdullah Khan|      100.0|\n|  Zoya Sheikh|      100.0|\n|   Sana Gupta|       45.0|\n| Ibrahim Khan|       30.0|\n+-------------+-----------+\n\nMost Enrolled Course\n+--------+-------------+-----------+\n|CourseID|   CourseName|EnrollCount|\n+--------+-------------+-----------+\n|    C001|Python Basics|          2|\n+--------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Join to find average progress per instructor\n",
    "#Show who teaches the most enrolled course\n",
    "catalog = spark.read.option(\"header\", True).option(\"inferSchema\", True) \\\n",
    "    .csv(\"file:/Workspace/Shared/course_catalog.csv\")\n",
    "joined = df.join(catalog, \"CourseID\", \"left\")\n",
    "print(\"Average Progress by Instructor\")\n",
    "joined.groupBy(\"Instructor\") \\\n",
    "      .agg(avg(\"ProgressPercent\").alias(\"AvgProgress\")) \\\n",
    "      .orderBy(col(\"AvgProgress\").desc()) \\\n",
    "      .show()\n",
    "print(\"Most Enrolled Course\")\n",
    "joined.groupBy(\"CourseID\",\"CourseName\") \\\n",
    "      .agg(count(\"*\").alias(\"EnrollCount\")) \\\n",
    "      .orderBy(col(\"EnrollCount\").desc()) \\\n",
    "      .limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d70923e-6458-42ad-9def-23aebfe464a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Delta Lake Practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319b0b14-c084-49c1-b754-79a9562b3b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|version|           timestamp|          userId|            userName|operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|      7|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          6|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      6|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          5|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      5|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          4|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n|      4|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          2|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      3|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          2|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      2|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          1|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n|      1|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|          0|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n|      0|2025-06-19 05:09:...|4833629471493945|azuser3545_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{1093877947262475}|0611-043339-3vb7b9iv|       NULL|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Save as Delta Table enrollments_delta\n",
    "joined.write.format(\"delta\").mode(\"overwrite\").save(\"file:/Workspace/Shared/enrollments_delta\")\n",
    "#Apply:\n",
    "#Update: Set all ratings to 5 where Course = 'Python Basics'\n",
    "#Delete: All rows where ProgressPercent = 0\n",
    "from delta.tables import DeltaTable\n",
    "dt = DeltaTable.forPath(spark, \"file:/Workspace/Shared/enrollments_delta\")\n",
    "dt.update(condition=\"CourseName = 'Python Basics'\", set={\"Rating\":\"5\"})\n",
    "dt.delete(condition=\"ProgressPercent = 0\")\n",
    "#Show DESCRIBE HISTORY\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`file:/Workspace/Shared/enrollments_delta`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91ee4a9c-f8bf-41a4-82e7-b161a96963da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Window Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44037ced-e7c4-4641-9e1a-778830388ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Use dense_rank() to rank courses by number of enrollments\n",
    "#lead() to find next course by each user (sorted by EnrollDate)\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import dense_rank, lead\n",
    "w1 = Window.orderBy(col(\"EnrollCount\").desc())\n",
    "course_rank = joined.groupBy(\"CourseID\",\"CourseName\") \\\n",
    "    .agg(count(\"*\").alias(\"EnrollCount\")) \\\n",
    "    .withColumn(\"Rank\", dense_rank().over(w1))\n",
    "w2 = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "joined = joined.withColumn(\"NextCourse\", lead(\"CourseName\").over(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ee100ad-6032-45f0-96df-8e04cbc5ac45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SQL Logic for Dashboard Views**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02919167-3e51-46fa-9746-fa3c06548e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create views:\n",
    "#daily_enrollments\n",
    "#category_performance (avg rating by category)\n",
    "#top_3_courses\n",
    "spark.sql(\"\"\"\n",
    "  CREATE OR REPLACE TEMP VIEW daily_enrollments AS\n",
    "  SELECT EnrollDate, COUNT(*) AS EnrollCount\n",
    "  FROM enrollments\n",
    "  GROUP BY EnrollDate\n",
    "\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "  CREATE OR REPLACE TEMP VIEW category_performance AS\n",
    "  SELECT Category, AVG(Rating) AS AvgRating\n",
    "  FROM enrollments\n",
    "  GROUP BY Category\n",
    "\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "  CREATE OR REPLACE TEMP VIEW top_3_courses AS\n",
    "  SELECT CourseID, CourseName, COUNT(*) AS EnrollCount\n",
    "  FROM enrollments\n",
    "  GROUP BY CourseID, CourseName\n",
    "  ORDER BY EnrollCount DESC\n",
    "  LIMIT 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "679889ce-2372-4cfc-9b42-438c0a73e63d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Time Travel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52fa310c-2143-476f-88f9-9f1ea1948347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+-------------+-------------+------------+\n|CourseID|EnrollID|UserID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|EngagementScore|   Instructor|DurationHours|       Level|\n+--------+--------+------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+-------------+-------------+------------+\n|    C001|    E001|  U001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|            400|Abdullah Khan|            8|    Beginner|\n|    C002|    E002|  U002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|              0|   Sana Gupta|            5|    Beginner|\n|    C003|    E003|  U001|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|              0| Ibrahim Khan|           10|Intermediate|\n|    C001|    E004|  U003|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|            500|Abdullah Khan|            8|    Beginner|\n|    C004|    E005|  U004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|            400|  Zoya Sheikh|            6|    Beginner|\n+--------+--------+------+-----------------+------------+----------+--------------+---------------+------+--------------+---------------+-------------+-------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#View previous version before update/delete\n",
    "spark.read.format(\"delta\")\\\n",
    "     .option(\"versionAsOf\", 0)\\\n",
    "     .load(\"file:/Workspace/Shared/enrollments_delta\")\\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a0540d-3b63-4455-b235-a41a7f63eb34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Export Reporting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90ec9dbb-82e2-4a5a-a9c8-80a53f244e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to JSON, partitioned by Category\n",
    "#Create summary DataFrame:CourseName, TotalEnrollments, AvgRating, AvgProgress\n",
    "#Save as Parque\n",
    "summary = joined.groupBy(\"Category\",\"CourseName\") \\\n",
    "  .agg(\n",
    "    count(\"*\").alias(\"TotalEnrollments\"),\n",
    "    avg(\"Rating\").alias(\"AvgRating\"),\n",
    "    avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
    "  )\n",
    "summary.write.mode(\"overwrite\") \\\n",
    "       .partitionBy(\"Category\") \\\n",
    "       .parquet(\"file:/Workspace/Shared/course_summary_parquet\")\n",
    "summary.write.mode(\"overwrite\") \\\n",
    "       .json(\"file:/Workspace/Shared/course_summary_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ea5a009-8c16-4809-b888-adcf29abc12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "june-19(set-2)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}